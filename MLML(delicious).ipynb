{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np \n",
    "import os\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, hamming_loss, zero_one_loss, coverage_error, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from time import strftime, localtime\n",
    "from sklearn.model_selection import KFold\n",
    "random.seed = 11\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is: 16105\n",
      "#features is: 500, #labels is: 983\n",
      "Ratio of positive labels is: 1.93%\n"
     ]
    }
   ],
   "source": [
    "# Reading dataset\n",
    "educationDataset = loadmat(\"/home/karim/Documents/research/sourceCode/MLML/mlml_weightedLoss/Datasets/MulanDatasets/delicious.mat\")\n",
    "\n",
    "features = educationDataset['train_data']\n",
    "test_features = educationDataset['test_data']\n",
    "\n",
    "labels = educationDataset['train_target'].T\n",
    "test_labels = educationDataset['test_target'].T\n",
    "\n",
    "\"\"\"\n",
    "Split ratio is strange: 40% training and 60% testing, we merge and data and resplit with 70/30 split\n",
    "\"\"\"\n",
    "features = np.append(features,test_features,axis = 0)\n",
    "labels = np.append(labels,test_labels,axis = 0)\n",
    "\n",
    "print(\"Number of samples is: {}\".format(len(features)))\n",
    "print(\"#features is: {}, #labels is: {}\".format(features.shape[1],labels.shape[1]))\n",
    "print(\"Ratio of positive labels is: {:.2f}%\".format(100 * labels.sum()/(labels.shape[0]*labels.shape[1])))\n",
    "\n",
    "splitter = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "#features, test_features, labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [
     0,
     1,
     6,
     12,
     18,
     27,
     52,
     68,
     78
    ]
   },
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    #variable_summaries(w)\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    #variable_summaries(b)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def weighted_loss(y_true, y_pred, positive_weights, negative_weights):\n",
    "    # clip to prevent NaN's and Inf's\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7, name=None)\n",
    "    #y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # calc\n",
    "    loss = (-y_true * tf.log(y_pred) * positive_weights) - ((1.0 - y_true) * tf.log(1.0 - y_pred) * negative_weights)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def evaluation_report(folds_metrics,evaluation_file_path,header_note):\n",
    "    metrics_mean = np.mean(folds_metrics, axis = 0)\n",
    "    metrics_std = np.std(folds_metrics, axis = 0) * 1.96 # for 95% confidence interval\n",
    "    print(header_note)\n",
    "    print(\"===================\")\n",
    "    print(\"Test set evaluation\")\n",
    "    print(\"Hamming loss is:{:.3f} (+/-{:.3f})\".format(metrics_mean[0],metrics_std[0]))\n",
    "    print(\"Zero-one loss is:{:.3f} (+/-{:.3f})\".format(metrics_mean[1],metrics_std[1]))\n",
    "    print(\"Coverage error is:{:.3f} (+/-{:.3f})\".format(metrics_mean[2],metrics_std[2]))\n",
    "    print(\"F1 is:{:.3f} (+/-{:.3f})\".format(metrics_mean[3],metrics_std[3]))\n",
    "    print(\"Recall is:{:.3f} (+/-{:.3f})\".format(metrics_mean[4],metrics_std[4]))\n",
    "    print(\"Precision is:{:.3f} (+/-{:.3f})\".format(metrics_mean[5],metrics_std[5]))\n",
    "    print(\"Average Precision is:{:.3f} (+/-{:.3f})\".format(metrics_mean[6],metrics_std[6]))\n",
    "    \n",
    "    with open(evaluation_file_path, \"a+\") as f:\n",
    "        f.write(\"===================\\n\" + header_note + \"\\n\")\n",
    "        f.write(\"Hamming loss is:{:.3f} (+/-{:.3f})\".format(metrics_mean[0],metrics_std[0]) + \"\\n\"+\n",
    "                \"Zero-one loss is:{:.3f} (+/-{:.3f})\".format(metrics_mean[1],metrics_std[1]) + \"\\n\"+\n",
    "                \"Coverage error is:{:.3f} (+/-{:.3f})\".format(metrics_mean[2],metrics_std[2]) + \"\\n\"+\n",
    "                \"F1 is:{:.3f} (+/-{:.3f})\".format(metrics_mean[3],metrics_std[3]) + \"\\n\"+\n",
    "                \"Recall is:{:.3f} (+/-{:.3f})\".format(metrics_mean[4],metrics_std[4]) + \"\\n\"+\n",
    "                \"Precision is:{:.3f} (+/-{:.3f})\".format(metrics_mean[5],metrics_std[5]) + \"\\n\"+\n",
    "                \"Average Precision is:{:.3f} (+/-{:.3f})\".format(metrics_mean[6],metrics_std[6])\n",
    "               + \"\\n\\n\")\n",
    "        \n",
    "def evaluation_metrics_per_fold(test_labels, test_probs):\n",
    "    # ignoring auc for now because of error of undefined case of a class with no ones\n",
    "    try:\n",
    "        auc = roc_auc_score(test_labels, val_output)\n",
    "    except:\n",
    "        pass\n",
    "    HL = hamming_loss(test_labels, np.round(test_probs))\n",
    "    one_loss = zero_one_loss(test_labels, np.round(test_probs))\n",
    "    cover = coverage_error(test_labels, test_probs)\n",
    "    f1 = f1_score(test_labels, np.round(test_probs),average=\"micro\")\n",
    "    recall = recall_score(test_labels, np.round(test_probs),average=\"micro\")\n",
    "    precision = precision_score(test_labels, np.round(test_probs),average=\"micro\")\n",
    "    average_precision = average_precision_score(test_labels, test_probs,average=\"micro\")\n",
    "    metrics = [HL, one_loss, cover, f1, recall, precision, average_precision]\n",
    "    return metrics\n",
    "         \n",
    "def hide_labels(train_labels,ratio_of_hidden_samples = 0.4):\n",
    "    ones_indices = np.nonzero(train_labels)\n",
    "    number_of_hidden_samples = int(len(ones_indices[0]) * ratio_of_hidden_samples)\n",
    "    random_indices = random.sample(list(np.arange(len(ones_indices[0]))),number_of_hidden_samples)\n",
    "    indices_to_hide = (ones_indices[0][random_indices] , ones_indices[1][random_indices])\n",
    "    labels_with_missing_positives = np.copy(train_labels)\n",
    "    for counter in range(number_of_hidden_samples):\n",
    "        labels_with_missing_positives[indices_to_hide[0][counter]][indices_to_hide[1][counter]] = 0\n",
    "    return labels_with_missing_positives, indices_to_hide\n",
    "\n",
    "def get_weights_for_hidden_labels(train_labels,indices_to_hide, pos_weights = 5):\n",
    "    train_negative_weights = np.zeros_like(train_labels) + 1 \n",
    "    train_positive_weights = np.zeros_like(train_labels) + pos_weights # We make positive weight 5 becuase of data imbalance\n",
    "    for counter in range (len(indices_to_hide[0])):\n",
    "        train_negative_weights[indices_to_hide[0][counter]][indices_to_hide[1][counter]] = 0\n",
    "    return train_negative_weights, train_positive_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1119 20:13:56.240886 140255472060160 deprecation.py:506] From <ipython-input-6-51a4f1d79c6b>:14: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "# Define a 3 layers network to train \n",
    "input_shape = features.shape[1]\n",
    "output_shape = labels.shape[1]\n",
    "hidden_layer_1_shape = 300\n",
    "hidden_layer_2_shape = 200\n",
    "hidden_layer_3_shape = 100\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, output_shape], name=\"true_labels\")\n",
    "x_input = tf.placeholder(tf.float32, [None,input_shape],name=\"input_layer\")\n",
    "current_keep_prob = tf.placeholder(tf.float32, name=\"dropout_rate\")\n",
    "h1 = tf.nn.tanh(full_layer(x_input, hidden_layer_1_shape))\n",
    "h2 = tf.nn.tanh(full_layer(h1, hidden_layer_2_shape))\n",
    "h3 = tf.nn.tanh(full_layer(h2, hidden_layer_3_shape))\n",
    "dropped = tf.nn.dropout(h3, keep_prob=current_keep_prob)\n",
    "logits = full_layer(dropped,output_shape)\n",
    "output = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Prepare results report \n",
    "Experiment_name = \"Education_weightedloss\"\n",
    "experiment_time = strftime(\"%d-%m_%H:%M\", localtime())\n",
    "saving_dir = \"/home/karim/Documents/research/sourceCode/MLML/mlml_weightedLoss/Experiment_results/\"\n",
    "exp_dir = os.path.join(saving_dir,Experiment_name,experiment_time)\n",
    "os.makedirs(exp_dir)\n",
    "model_output_dir = os.path.join(exp_dir,\"model_output\")\n",
    "os.mkdir(model_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "# using weighted cross entropy because dataset is sparse and we need to weight positives more\n",
    "#loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "POSITIVE_WEIGHT = 5\n",
    "loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=logits, labels=y,pos_weight = POSITIVE_WEIGHT))\n",
    "\n",
    "# Learning rate decay\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step, decay_steps=1000,\n",
    "                                          decay_rate=0.95,staircase=True)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "correct_prediction = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Evaluate on fold 1\n",
      "Epoch #3000 LR: 0.0857 Loss: 0.3084 accuracy: 0.9551 Test loss: 0.2533 Test accuracy: 0.9723\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2842 accuracy: 0.9621 Test loss: 0.2464 Test accuracy: 0.9724\n",
      "Epoch #9000 LR: 0.0630 Loss: 0.2758 accuracy: 0.9644 Test loss: 0.2447 Test accuracy: 0.9726\n",
      "Epoch #12000 LR: 0.0540 Loss: 0.2704 accuracy: 0.9660 Test loss: 0.2434 Test accuracy: 0.9729\n",
      "Epoch #15000 LR: 0.0463 Loss: 0.2677 accuracy: 0.9671 Test loss: 0.2422 Test accuracy: 0.9732\n",
      "Train/Evaluate on fold 2\n",
      "Epoch #3000 LR: 0.0857 Loss: 0.3089 accuracy: 0.9550 Test loss: 0.2531 Test accuracy: 0.9724\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2848 accuracy: 0.9619 Test loss: 0.2461 Test accuracy: 0.9725\n",
      "Epoch #9000 LR: 0.0630 Loss: 0.2760 accuracy: 0.9641 Test loss: 0.2447 Test accuracy: 0.9726\n",
      "Epoch #12000 LR: 0.0540 Loss: 0.2712 accuracy: 0.9656 Test loss: 0.2437 Test accuracy: 0.9727\n",
      "Epoch #15000 LR: 0.0463 Loss: 0.2680 accuracy: 0.9668 Test loss: 0.2428 Test accuracy: 0.9728\n",
      "Train/Evaluate on fold 3\n",
      "Epoch #3000 LR: 0.0857 Loss: 0.3083 accuracy: 0.9549 Test loss: 0.2516 Test accuracy: 0.9725\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2849 accuracy: 0.9618 Test loss: 0.2455 Test accuracy: 0.9725\n",
      "Epoch #9000 LR: 0.0630 Loss: 0.2765 accuracy: 0.9641 Test loss: 0.2441 Test accuracy: 0.9727\n",
      "Epoch #12000 LR: 0.0540 Loss: 0.2717 accuracy: 0.9657 Test loss: 0.2431 Test accuracy: 0.9728\n",
      "Epoch #15000 LR: 0.0463 Loss: 0.2687 accuracy: 0.9668 Test loss: 0.2422 Test accuracy: 0.9730\n",
      "Train/Evaluate on fold 4\n",
      "Epoch #3000 LR: 0.0857 Loss: 0.3083 accuracy: 0.9551 Test loss: 0.2512 Test accuracy: 0.9727\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2850 accuracy: 0.9617 Test loss: 0.2452 Test accuracy: 0.9729\n",
      "Epoch #9000 LR: 0.0630 Loss: 0.2769 accuracy: 0.9639 Test loss: 0.2438 Test accuracy: 0.9729\n",
      "Epoch #12000 LR: 0.0540 Loss: 0.2720 accuracy: 0.9654 Test loss: 0.2428 Test accuracy: 0.9730\n",
      "Epoch #15000 LR: 0.0463 Loss: 0.2685 accuracy: 0.9666 Test loss: 0.2418 Test accuracy: 0.9732\n",
      "Train/Evaluate on fold 5\n",
      "Epoch #3000 LR: 0.0857 Loss: 0.3091 accuracy: 0.9549 Test loss: 0.2526 Test accuracy: 0.9724\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2846 accuracy: 0.9620 Test loss: 0.2459 Test accuracy: 0.9726\n",
      "Epoch #9000 LR: 0.0630 Loss: 0.2764 accuracy: 0.9643 Test loss: 0.2444 Test accuracy: 0.9727\n",
      "Epoch #12000 LR: 0.0540 Loss: 0.2714 accuracy: 0.9658 Test loss: 0.2433 Test accuracy: 0.9728\n",
      "Epoch #15000 LR: 0.0463 Loss: 0.2683 accuracy: 0.9669 Test loss: 0.2423 Test accuracy: 0.9729\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "NUM_EPOCHS = 15000\n",
    "\n",
    "fold = 0\n",
    "folds_metrics = []\n",
    "for train_index, test_index in splitter.split(features, labels):\n",
    "    fold += 1\n",
    "    print(\"Train/Evaluate on fold %d\" % fold)\n",
    "    train_features, test_features = features[train_index], features[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                             train_features,y: train_labels,\n",
    "                                                                                             current_keep_prob: 0.3,})\n",
    "            if (epoch+1)% 3000 == 0:\n",
    "                val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                              x_input: test_features,\n",
    "                                                                                              y:test_labels,\n",
    "                                                                                              current_keep_prob: 1.0})\n",
    "                print(\"Epoch #{}\".format(epoch+1), \"LR: {:.4f}\".format(current_learning_rate),\n",
    "                      \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                      \"accuracy: {:.4f}\".format(epoch_accuracy),\n",
    "                      \"Test loss: {:.4f}\".format(val_losses), \n",
    "                      \"Test accuracy: {:.4f}\".format(val_accuracies))\n",
    "    np.savetxt(os.path.join(model_output_dir,'[complete]groundtruth_' + str(fold) + '.out'), test_labels, delimiter=',')\n",
    "    np.savetxt(os.path.join(model_output_dir, '[complete]output' + str(fold) + '.out'), val_output, delimiter=',')\n",
    "    folds_metrics.append(evaluation_metrics_per_fold(test_labels,val_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthresholds = np.arange(0, 1, 0.01)\\nf1_array = np.zeros((output_shape, len(thresholds)))\\nfor idx in range(output_shape):\\n    f1_array[idx, :] = [\\n        f1_score(train_labels[:, idx], np.clip(np.round(epoch_output[:, idx] - threshold + 0.5), 0, 1))\\n        for threshold in thresholds]\\nthreshold_arg = np.argmax(f1_array, axis=1)\\nthreshold_per_class = thresholds[threshold_arg]\\n\\n# Applying thresholds optimized per class\\nmodel_output_rounded = np.zeros_like(epoch_output)\\nfor idx in range(output_shape):\\n    model_output_rounded[:, idx] = np.clip(np.round(epoch_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting threshold \n",
    "\"\"\"\n",
    "thresholds = np.arange(0, 1, 0.01)\n",
    "f1_array = np.zeros((output_shape, len(thresholds)))\n",
    "for idx in range(output_shape):\n",
    "    f1_array[idx, :] = [\n",
    "        f1_score(train_labels[:, idx], np.clip(np.round(epoch_output[:, idx] - threshold + 0.5), 0, 1))\n",
    "        for threshold in thresholds]\n",
    "threshold_arg = np.argmax(f1_array, axis=1)\n",
    "threshold_per_class = thresholds[threshold_arg]\n",
    "\n",
    "# Applying thresholds optimized per class\n",
    "model_output_rounded = np.zeros_like(epoch_output)\n",
    "for idx in range(output_shape):\n",
    "    model_output_rounded[:, idx] = np.clip(np.round(epoch_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing labels\n",
      "===================\n",
      "Test set evaluation\n",
      "Hamming loss is:0.027 (+/-0.000)\n",
      "Zero-one loss is:1.000 (+/-0.000)\n",
      "Coverage error is:698.659 (+/-6.723)\n",
      "F1 is:0.246 (+/-0.004)\n",
      "Recall is:0.228 (+/-0.002)\n",
      "Precision is:0.268 (+/-0.007)\n",
      "Average Precision is:0.175 (+/-0.007)\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "evaluation_report(folds_metrics,os.path.join(exp_dir,\"evaluation_report.txt\"),\"No missing labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Evaluate on fold 1\n",
      "Epoch #2000 LR: 0.0903 Loss: 0.2679 accuracy: 0.9603 Test loss: 0.2709 Test accuracy: 0.9787\n",
      "Epoch #4000 LR: 0.0815 Loss: 0.2198 accuracy: 0.9756 Test loss: 0.2598 Test accuracy: 0.9787\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2084 accuracy: 0.9779 Test loss: 0.2603 Test accuracy: 0.9787\n",
      "Epoch #8000 LR: 0.0663 Loss: 0.2032 accuracy: 0.9790 Test loss: 0.2607 Test accuracy: 0.9787\n",
      "Epoch #10000 LR: 0.0599 Loss: 0.2006 accuracy: 0.9796 Test loss: 0.2608 Test accuracy: 0.9787\n",
      "Epoch #12000 LR: 0.0540 Loss: 0.1980 accuracy: 0.9803 Test loss: 0.2607 Test accuracy: 0.9787\n",
      "Epoch #14000 LR: 0.0488 Loss: 0.1964 accuracy: 0.9808 Test loss: 0.2604 Test accuracy: 0.9788\n",
      "Train/Evaluate on fold 2\n",
      "Epoch #2000 LR: 0.0903 Loss: 0.2676 accuracy: 0.9594 Test loss: 0.2681 Test accuracy: 0.9788\n",
      "Epoch #4000 LR: 0.0815 Loss: 0.2204 accuracy: 0.9752 Test loss: 0.2584 Test accuracy: 0.9788\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2093 accuracy: 0.9774 Test loss: 0.2593 Test accuracy: 0.9789\n",
      "Epoch #8000 LR: 0.0663 Loss: 0.2042 accuracy: 0.9786 Test loss: 0.2598 Test accuracy: 0.9789\n"
     ]
    }
   ],
   "source": [
    "# Training with missing labels with 40%\n",
    "NUM_EPOCHS = 15000\n",
    "\n",
    "fold = 0\n",
    "folds_metrics = []\n",
    "for train_index, test_index in splitter.split(features, labels):\n",
    "    fold += 1\n",
    "    print(\"Train/Evaluate on fold %d\" % fold)\n",
    "    train_features, test_features = features[train_index], features[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    labels_with_missing_positives, indices_to_hide = hide_labels(train_labels,0.4)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                             train_features,y: labels_with_missing_positives,\n",
    "                                                                                             current_keep_prob: 0.3})\n",
    "            if (epoch+1)% 2000 == 0:\n",
    "                val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                              x_input: test_features,\n",
    "                                                                                              y:test_labels,\n",
    "                                                                                              current_keep_prob: 1.0})\n",
    "                print(\"Epoch #{}\".format(epoch+1),  \"LR: {:.4f}\".format(current_learning_rate),\n",
    "                      \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                      \"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                      \"Test loss: {:.4f}\".format(val_losses), \n",
    "                      \"Test accuracy: {:.4f}\".format(val_accuracies))\n",
    "    np.savetxt(os.path.join(model_output_dir,'[missing]groundtruth_' + str(fold) + '.out'), test_labels, delimiter=',')\n",
    "    np.savetxt(os.path.join(model_output_dir, '[missing]output' + str(fold) + '.out'), val_output, delimiter=',')\n",
    "    folds_metrics.append(evaluation_metrics_per_fold(test_labels,val_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "evaluation_report(folds_metrics,os.path.join(exp_dir,\"evaluation_report.txt\"),\n",
    "                  \"40% missing labels, no weighted loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With fixed negative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Adding the weighted loss to the model\n",
    "positive_weights = tf.placeholder(tf.float32, [None,output_shape], name = \"Positive_weights\")\n",
    "negative_weights = tf.placeholder(tf.float32, [None, output_shape], name=\"negative_weights\")\n",
    "my_weights_loss = weighted_loss(y_true= y, y_pred= output,\n",
    "                              positive_weights= positive_weights, negative_weights= negative_weights)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(my_weights_loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training with negative weights!\n",
    "NUM_EPOCHS = 15000\n",
    "\n",
    "fold = 0\n",
    "folds_metrics = []\n",
    "for train_index, test_index in splitter.split(features, labels):\n",
    "    fold += 1\n",
    "    print(\"Train/Evaluate on fold %d\" % fold)\n",
    "    train_features, test_features = features[train_index], features[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    labels_with_missing_positives, indices_to_hide = hide_labels(train_labels,0.4)\n",
    "    train_negative_weights, train_positive_weights = get_weights_for_hidden_labels(train_labels,indices_to_hide)\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            epoch_my_weights_loss, epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([my_weights_loss, loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                             train_features,y: labels_with_missing_positives,positive_weights: train_positive_weights,\n",
    "                                                                                                      negative_weights: train_negative_weights,\n",
    "                                                                                                      current_keep_prob: 0.3})\n",
    "            if (epoch+1)% 5000 == 0:\n",
    "                val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                              x_input: test_features,\n",
    "                                                                                              y:test_labels,\n",
    "                                                                                              current_keep_prob: 1.0})\n",
    "                print(\"Epoch #{}\".format(epoch+1),  \"LR: {:.4f}\".format(current_learning_rate),\n",
    "                      \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                      \"Weighted Loss: {:.4f}\".format(epoch_my_weights_loss),\"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                      \"Test loss: {:.4f}\".format(val_losses), \"Test accuracy: {:.4f}\".format(val_accuracies))\n",
    "    np.savetxt(os.path.join(model_output_dir,'[weighted]groundtruth_' + str(fold) + '.out'), test_labels, delimiter=',')\n",
    "    np.savetxt(os.path.join(model_output_dir, '[weighted]output' + str(fold) + '.out'), val_output, delimiter=',')\n",
    "    folds_metrics.append(evaluation_metrics_per_fold(test_labels,val_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Evaluation\n",
    "evaluation_report(folds_metrics,os.path.join(exp_dir,\"evaluation_report.txt\"),\n",
    "                  \"Weighted loss with 40% missing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
