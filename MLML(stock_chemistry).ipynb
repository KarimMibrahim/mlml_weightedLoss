{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "random.seed = 0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is: 6961\n",
      "Ratio of positive labels is: 1.21%\n"
     ]
    }
   ],
   "source": [
    "stack_chemistry = loadmat(\"/home/karim/Documents/research/sourceCode/MLML/mlml_weightedLoss/Datasets/junHuang/stack/Stackex_chemistry.mat\")\n",
    "\n",
    "features = stack_chemistry['data']\n",
    "features_df = pd.DataFrame(features)\n",
    "\n",
    "labels = stack_chemistry['target'].T\n",
    "labels_df = pd.DataFrame(labels)\n",
    "print(\"Number of training samples is: {}\".format(len(features)))\n",
    "print(\"Ratio of positive labels is: {:.2f}%\".format(100 * labels.sum()/(labels.shape[0]*labels.shape[1])))\n",
    "\n",
    "#LABEL_LIST = list(features_labels_df.columns[-174:])\n",
    "\n",
    "features, test_features, labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     5,
     10,
     16,
     22
    ]
   },
   "outputs": [],
   "source": [
    "input_shape = features.shape[1]\n",
    "output_shape = labels.shape[1]\n",
    "hidden_layer_1_shape = 240\n",
    "hidden_layer_2_shape = 120\n",
    "\n",
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    #variable_summaries(w)\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    #variable_summaries(b)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def weighted_loss(y_true, y_pred, positive_weights, negative_weights):\n",
    "    # clip to prevent NaN's and Inf's\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7, name=None)\n",
    "    #y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # calc\n",
    "    loss = (-y_true * tf.log(y_pred) * positive_weights) - ((1.0 - y_true) * tf.log(1.0 - y_pred) * negative_weights)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 2 layers network to train \n",
    "y = tf.placeholder(tf.float32, [None, output_shape], name=\"true_labels\")\n",
    "x_input = tf.placeholder(tf.float32, [None,input_shape],name=\"input_layer\")\n",
    "h1 = tf.nn.tanh(full_layer(x_input, hidden_layer_1_shape))\n",
    "h2 = tf.nn.tanh(full_layer(h1, hidden_layer_2_shape))\n",
    "#h3 = tf.nn.relu(full_layer(h2, hidden_layer_2_shape))\n",
    "#h4 = tf.nn.relu(full_layer(h3, hidden_layer_2_shape))\n",
    "logits = full_layer(h2,output_shape)\n",
    "output = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using weighted cross entropy because dataset is sparse and we need to weight positives more\n",
    "#loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=logits, labels=y,pos_weight = 10))\n",
    "\n",
    "\n",
    "# Learning rate decay\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step, decay_steps=1000,\n",
    "                                          decay_rate=0.95,staircase=True)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "correct_prediction = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 Loss: 0.3210 accuracy: 0.9734 Test loss: 0.3198 Test accuracy: 0.9732\n",
      "Epoch #1000 Loss: 0.2951 accuracy: 0.9746 Test loss: 0.2948 Test accuracy: 0.9744\n",
      "Epoch #1500 Loss: 0.2881 accuracy: 0.9751 Test loss: 0.2889 Test accuracy: 0.9748\n",
      "Epoch #2000 Loss: 0.2821 accuracy: 0.9756 Test loss: 0.2839 Test accuracy: 0.9752\n",
      "Epoch #2500 Loss: 0.2762 accuracy: 0.9760 Test loss: 0.2790 Test accuracy: 0.9758\n",
      "Epoch #3000 Loss: 0.2703 accuracy: 0.9765 Test loss: 0.2742 Test accuracy: 0.9762\n",
      "Epoch #3500 Loss: 0.2649 accuracy: 0.9769 Test loss: 0.2697 Test accuracy: 0.9767\n",
      "Epoch #4000 Loss: 0.2597 accuracy: 0.9773 Test loss: 0.2655 Test accuracy: 0.9770\n",
      "Epoch #4500 Loss: 0.2551 accuracy: 0.9775 Test loss: 0.2619 Test accuracy: 0.9772\n",
      "Epoch #5000 Loss: 0.2507 accuracy: 0.9777 Test loss: 0.2585 Test accuracy: 0.9773\n",
      "Epoch #5500 Loss: 0.2468 accuracy: 0.9778 Test loss: 0.2555 Test accuracy: 0.9773\n",
      "Epoch #6000 Loss: 0.2431 accuracy: 0.9779 Test loss: 0.2528 Test accuracy: 0.9773\n",
      "Epoch #6500 Loss: 0.2398 accuracy: 0.9780 Test loss: 0.2504 Test accuracy: 0.9773\n",
      "Epoch #7000 Loss: 0.2367 accuracy: 0.9781 Test loss: 0.2482 Test accuracy: 0.9773\n",
      "Epoch #7500 Loss: 0.2338 accuracy: 0.9781 Test loss: 0.2462 Test accuracy: 0.9773\n",
      "Epoch #8000 Loss: 0.2311 accuracy: 0.9781 Test loss: 0.2444 Test accuracy: 0.9773\n",
      "Epoch #8500 Loss: 0.2286 accuracy: 0.9782 Test loss: 0.2427 Test accuracy: 0.9774\n",
      "Epoch #9000 Loss: 0.2261 accuracy: 0.9782 Test loss: 0.2412 Test accuracy: 0.9773\n",
      "Epoch #9500 Loss: 0.2239 accuracy: 0.9782 Test loss: 0.2398 Test accuracy: 0.9773\n",
      "Epoch #10000 Loss: 0.2218 accuracy: 0.9783 Test loss: 0.2385 Test accuracy: 0.9773\n",
      "======================================                       \n",
      "\n",
      "Final test accuracy: 0.9773\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 10000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels,})\n",
    "        if (epoch+1)% 500 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels})\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"accuracy: {:.4f}\".format(epoch_accuracy),\n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \n",
    "                  \"Test accuracy: {:.4f}\".format(val_accuracies))\n",
    "            if (epoch+1) == NUM_EPOCHS:\n",
    "                print(\"====================================== \\\n",
    "                      \\n\\nFinal test accuracy: {:.4f}\".format(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC is:0.840\n",
      "F1 is:0.099\n",
      "Recall is:0.119\n",
      "Precision is:0.159\n",
      "Hamming loss is:0.022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# On training \n",
    "print(\"AUC is:{:.3f}\".format(roc_auc_score(labels, epoch_output)))\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(labels, np.round(epoch_output))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# Adjusting threshold \n",
    "thresholds = np.arange(0, 1, 0.01)\n",
    "f1_array = np.zeros((output_shape, len(thresholds)))\n",
    "for idx in range(output_shape):\n",
    "    f1_array[idx, :] = [\n",
    "        f1_score(labels[:, idx], np.clip(np.round(epoch_output[:, idx] - threshold + 0.5), 0, 1))\n",
    "        for threshold in thresholds]\n",
    "threshold_arg = np.argmax(f1_array, axis=1)\n",
    "threshold_per_class = thresholds[threshold_arg]\n",
    "\n",
    "# Applying thresholds optimized per class\n",
    "model_output_rounded = np.zeros_like(epoch_output)\n",
    "for idx in range(output_shape):\n",
    "    model_output_rounded[:, idx] = np.clip(np.round(epoch_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 is:0.207\n",
      "Recall is:0.312\n",
      "Precision is:0.245\n",
      "Hamming loss is:0.052\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 is:{:.3f}\".format(f1_score(labels, model_output_rounded,average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(labels, model_output_rounded,average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(labels, model_output_rounded,average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(labels, model_output_rounded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying thresholds optimized per class for testset\n",
    "test_output_rounded = np.zeros_like(val_output)\n",
    "for idx in range(output_shape):\n",
    "    test_output_rounded[:, idx] = np.clip(np.round(val_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 is:0.070\n",
      "Recall is:0.091\n",
      "Precision is:0.093\n",
      "Hamming loss is:0.023\n",
      "After treshold optimization\n",
      "F1 is:0.103\n",
      "Recall is:0.162\n",
      "Precision is:0.104\n",
      "Hamming loss is:0.055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1439: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# On test\n",
    "#print(\"AUC is:{:.3f}\".format(roc_auc_score(test_labels, val_output)))\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(test_labels, np.round(val_output))))\n",
    "print(\"After treshold optimization\")\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(test_labels, test_output_rounded,average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(test_labels,test_output_rounded,average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(test_labels, test_output_rounded,average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(test_labels, test_output_rounded)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 Loss: 0.2375 accuracy: 0.9880 Test loss: 0.3182 Test accuracy: 0.9842\n",
      "Epoch #1000 Loss: 0.2139 accuracy: 0.9879 Test loss: 0.3042 Test accuracy: 0.9841\n",
      "Epoch #1500 Loss: 0.2093 accuracy: 0.9880 Test loss: 0.3015 Test accuracy: 0.9842\n",
      "Epoch #2000 Loss: 0.2064 accuracy: 0.9880 Test loss: 0.2990 Test accuracy: 0.9844\n",
      "Epoch #2500 Loss: 0.2038 accuracy: 0.9881 Test loss: 0.2964 Test accuracy: 0.9846\n",
      "Epoch #3000 Loss: 0.2012 accuracy: 0.9882 Test loss: 0.2934 Test accuracy: 0.9847\n",
      "Epoch #3500 Loss: 0.1986 accuracy: 0.9883 Test loss: 0.2904 Test accuracy: 0.9849\n",
      "Epoch #4000 Loss: 0.1961 accuracy: 0.9883 Test loss: 0.2874 Test accuracy: 0.9851\n",
      "Epoch #4500 Loss: 0.1937 accuracy: 0.9883 Test loss: 0.2846 Test accuracy: 0.9851\n",
      "Epoch #5000 Loss: 0.1913 accuracy: 0.9883 Test loss: 0.2819 Test accuracy: 0.9851\n"
     ]
    }
   ],
   "source": [
    "ones_indices = np.nonzero(labels)\n",
    "ratio_of_hidden_samples = 0.4\n",
    "number_of_hidden_samples = int(len(ones_indices[0]) * ratio_of_hidden_samples)\n",
    "random_indices = random.sample(list(np.arange(len(ones_indices[0]))),number_of_hidden_samples)\n",
    "indices_to_hide = (ones_indices[0][random_indices] , ones_indices[1][random_indices])\n",
    "labels_with_missing_positives = np.copy(labels)\n",
    "for counter in range (number_of_hidden_samples):\n",
    "    labels_with_missing_positives[indices_to_hide[0][counter]][indices_to_hide[1][counter]] = 0\n",
    "    \n",
    "    \n",
    "# Training with missing labels with 40%\n",
    "NUM_EPOCHS = 5000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels_with_missing_positives})\n",
    "        if (epoch+1)% 500 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels})\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \n",
    "                  \"Test accuracy: {:.4f}\".format(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjusting threshold \n",
    "thresholds = np.arange(0, 1, 0.01)\n",
    "f1_array = np.zeros((output_shape, len(thresholds)))\n",
    "for idx in range(output_shape):\n",
    "    f1_array[idx, :] = [\n",
    "        f1_score(labels[:, idx], np.clip(np.round(epoch_output[:, idx] - threshold + 0.5), 0, 1))\n",
    "        for threshold in thresholds]\n",
    "threshold_arg = np.argmax(f1_array, axis=1)\n",
    "threshold_per_class = thresholds[threshold_arg]\n",
    "\n",
    "# Applying thresholds optimized per class\n",
    "model_output_rounded = np.zeros_like(epoch_output)\n",
    "for idx in range(output_shape):\n",
    "    model_output_rounded[:, idx] = np.clip(np.round(epoch_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set evaluation\n",
      "AUC is:0.688\n",
      "F1 is:0.021\n",
      "Recall is:0.020\n",
      "Precision is:0.056\n",
      "Hamming loss is:0.015\n",
      "F1 is:0.096\n",
      "Recall is:0.343\n",
      "Precision is:0.104\n",
      "Hamming loss is:0.187\n",
      "===================\n",
      "Test set evaluation\n",
      "F1 is:0.017\n",
      "Recall is:0.017\n",
      "Precision is:0.045\n",
      "Hamming loss is:0.015\n",
      "After treshold optimization\n",
      "F1 is:0.061\n",
      "Recall is:0.274\n",
      "Precision is:0.054\n",
      "Hamming loss is:0.190\n"
     ]
    }
   ],
   "source": [
    "# On training \n",
    "print(\"Training set evaluation\")\n",
    "print(\"AUC is:{:.3f}\".format(roc_auc_score(labels, epoch_output)))\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(labels, np.round(epoch_output))))\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(labels, model_output_rounded,average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(labels, model_output_rounded,average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(labels, model_output_rounded,average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(labels, model_output_rounded)))\n",
    " \n",
    "    \n",
    "# Applying thresholds optimized per class for testset\n",
    "test_output_rounded = np.zeros_like(val_output)\n",
    "for idx in range(output_shape):\n",
    "    test_output_rounded[:, idx] = np.clip(np.round(val_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)\n",
    "\n",
    "# On test\n",
    "print(\"===================\")\n",
    "print(\"Test set evaluation\")\n",
    "#print(\"AUC is:{:.3f}\".format(roc_auc_score(test_labels, val_output)))\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(test_labels, np.round(val_output))))\n",
    "print(\"After treshold optimization\")\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(test_labels, test_output_rounded,average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(test_labels,test_output_rounded,average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(test_labels, test_output_rounded,average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(test_labels, test_output_rounded)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With fixed negative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_negative_weights = np.zeros_like(labels) + 1 \n",
    "train_positive_weights = np.zeros_like(labels) + 10 # Due to imbalance increase wight of positive labels\n",
    "for counter in range (number_of_hidden_samples):\n",
    "    train_negative_weights[indices_to_hide[0][counter]][indices_to_hide[1][counter]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_weights = tf.placeholder(tf.float32, [None,output_shape], name = \"Positive_weights\")\n",
    "negative_weights = tf.placeholder(tf.float32, [None, output_shape], name=\"negative_weights\")\n",
    "my_weights_loss = weighted_loss(y_true= y, y_pred= output,\n",
    "                              positive_weights= positive_weights, negative_weights= negative_weights)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(my_weights_loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 Loss: 0.2394 Weighted Loss: 0.2379 accuracy: 0.9866 Test loss: 0.3189 Test accuracy: 0.9829\n",
      "Epoch #1000 Loss: 0.2141 Weighted Loss: 0.2126 accuracy: 0.9869 Test loss: 0.3037 Test accuracy: 0.9833\n",
      "Epoch #1500 Loss: 0.2094 Weighted Loss: 0.2080 accuracy: 0.9871 Test loss: 0.3010 Test accuracy: 0.9835\n",
      "Epoch #2000 Loss: 0.2065 Weighted Loss: 0.2050 accuracy: 0.9873 Test loss: 0.2987 Test accuracy: 0.9837\n",
      "Epoch #2500 Loss: 0.2040 Weighted Loss: 0.2025 accuracy: 0.9875 Test loss: 0.2963 Test accuracy: 0.9839\n",
      "Epoch #3000 Loss: 0.2014 Weighted Loss: 0.1999 accuracy: 0.9877 Test loss: 0.2936 Test accuracy: 0.9842\n",
      "Epoch #3500 Loss: 0.1989 Weighted Loss: 0.1973 accuracy: 0.9879 Test loss: 0.2908 Test accuracy: 0.9844\n",
      "Epoch #4000 Loss: 0.1964 Weighted Loss: 0.1947 accuracy: 0.9880 Test loss: 0.2880 Test accuracy: 0.9845\n",
      "Epoch #4500 Loss: 0.1940 Weighted Loss: 0.1923 accuracy: 0.9881 Test loss: 0.2853 Test accuracy: 0.9847\n",
      "Epoch #5000 Loss: 0.1917 Weighted Loss: 0.1899 accuracy: 0.9881 Test loss: 0.2827 Test accuracy: 0.9848\n",
      "Epoch #5500 Loss: 0.1895 Weighted Loss: 0.1877 accuracy: 0.9881 Test loss: 0.2803 Test accuracy: 0.9848\n",
      "Epoch #6000 Loss: 0.1873 Weighted Loss: 0.1855 accuracy: 0.9880 Test loss: 0.2779 Test accuracy: 0.9849\n",
      "Epoch #6500 Loss: 0.1854 Weighted Loss: 0.1834 accuracy: 0.9880 Test loss: 0.2758 Test accuracy: 0.9849\n",
      "Epoch #7000 Loss: 0.1834 Weighted Loss: 0.1814 accuracy: 0.9879 Test loss: 0.2738 Test accuracy: 0.9849\n",
      "Epoch #7500 Loss: 0.1816 Weighted Loss: 0.1796 accuracy: 0.9879 Test loss: 0.2720 Test accuracy: 0.9849\n",
      "Epoch #8000 Loss: 0.1799 Weighted Loss: 0.1778 accuracy: 0.9879 Test loss: 0.2702 Test accuracy: 0.9848\n",
      "Epoch #8500 Loss: 0.1783 Weighted Loss: 0.1761 accuracy: 0.9878 Test loss: 0.2686 Test accuracy: 0.9848\n",
      "Epoch #9000 Loss: 0.1767 Weighted Loss: 0.1745 accuracy: 0.9877 Test loss: 0.2671 Test accuracy: 0.9847\n",
      "Epoch #9500 Loss: 0.1752 Weighted Loss: 0.1729 accuracy: 0.9877 Test loss: 0.2657 Test accuracy: 0.9847\n",
      "Epoch #10000 Loss: 0.1738 Weighted Loss: 0.1715 accuracy: 0.9877 Test loss: 0.2644 Test accuracy: 0.9847\n"
     ]
    }
   ],
   "source": [
    "# Training with negative weights!\n",
    "NUM_EPOCHS = 10000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_my_weights_loss, epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([my_weights_loss, loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels_with_missing_positives,positive_weights: train_positive_weights,\n",
    "                                                                                                  negative_weights: train_negative_weights})\n",
    "        if (epoch+1)% 500 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels})\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"Weighted Loss: {:.4f}\".format(epoch_my_weights_loss),\"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \"Test accuracy: {:.4f}\".format(val_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "175"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
