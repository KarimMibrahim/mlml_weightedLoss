{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy\n",
    "from scipy.io import arff\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, hamming_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "random.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples is: 502\n"
     ]
    }
   ],
   "source": [
    "CAL_data_train = scipy.io.arff.loadarff(\"/home/karim/Documents/research/MLML datasets/CAL500/CAL500.arff\")\n",
    "\n",
    "features_labels = CAL_data_train[0]\n",
    "features_labels_df = pd.DataFrame(features_labels)\n",
    "print(\"Number of training samples is: {}\".format(len(CAL_data_train[0])))\n",
    "features = features_labels_df.values[:,:-174]\n",
    "labels = features_labels_df.values[:,-174:]\n",
    "LABEL_LIST = list(features_labels_df.columns[-174:])\n",
    "\n",
    "features, test_features, labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     5,
     10,
     16,
     22
    ]
   },
   "outputs": [],
   "source": [
    "input_shape = 68\n",
    "output_shape = 174\n",
    "hidden_layer_1_shape = 48\n",
    "hidden_layer_2_shape = 24\n",
    "\n",
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    #variable_summaries(w)\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    #variable_summaries(b)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def weighted_loss(y_true, y_pred, positive_weights, negative_weights):\n",
    "    # clip to prevent NaN's and Inf's\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7, name=None)\n",
    "    #y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # calc\n",
    "    loss = (-y_true * tf.log(y_pred) * positive_weights) - ((1.0 - y_true) * tf.log(1.0 - y_pred) * negative_weights)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a 2 layers network to train \n",
    "y = tf.placeholder(tf.float32, [None, output_shape], name=\"true_labels\")\n",
    "x_input = tf.placeholder(tf.float32, [None,input_shape],name=\"input_layer\")\n",
    "h1 = tf.nn.relu(full_layer(x_input, hidden_layer_1_shape))\n",
    "h2 = tf.nn.relu(full_layer(h1, hidden_layer_2_shape))\n",
    "#h3 = tf.nn.relu(full_layer(h2, hidden_layer_2_shape))\n",
    "#h4 = tf.nn.relu(full_layer(h3, hidden_layer_2_shape))\n",
    "logits = full_layer(h2,output_shape)\n",
    "output = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "# Learning rate decay\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step, decay_steps=1000,\n",
    "                                          decay_rate=0.95,staircase=True)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "correct_prediction = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 Loss: 0.3326 accuracy: 0.8631 Test loss: 0.3344 Test accuracy: 0.8616\n",
      "Epoch #1000 Loss: 0.3325 accuracy: 0.8631 Test loss: 0.3344 Test accuracy: 0.8616\n",
      "Epoch #1500 Loss: 0.3324 accuracy: 0.8632 Test loss: 0.3343 Test accuracy: 0.8617\n",
      "Epoch #2000 Loss: 0.3324 accuracy: 0.8633 Test loss: 0.3342 Test accuracy: 0.8617\n",
      "Epoch #2500 Loss: 0.3323 accuracy: 0.8633 Test loss: 0.3341 Test accuracy: 0.8617\n",
      "Epoch #3000 Loss: 0.3323 accuracy: 0.8634 Test loss: 0.3341 Test accuracy: 0.8617\n",
      "Epoch #3500 Loss: 0.3322 accuracy: 0.8634 Test loss: 0.3340 Test accuracy: 0.8617\n",
      "Epoch #4000 Loss: 0.3322 accuracy: 0.8635 Test loss: 0.3339 Test accuracy: 0.8617\n",
      "Epoch #4500 Loss: 0.3321 accuracy: 0.8635 Test loss: 0.3339 Test accuracy: 0.8617\n",
      "Epoch #5000 Loss: 0.3321 accuracy: 0.8636 Test loss: 0.3338 Test accuracy: 0.8617\n",
      "Epoch #5500 Loss: 0.3320 accuracy: 0.8636 Test loss: 0.3337 Test accuracy: 0.8617\n",
      "Epoch #6000 Loss: 0.3320 accuracy: 0.8636 Test loss: 0.3337 Test accuracy: 0.8617\n",
      "Epoch #6500 Loss: 0.3319 accuracy: 0.8636 Test loss: 0.3336 Test accuracy: 0.8617\n",
      "Epoch #7000 Loss: 0.3319 accuracy: 0.8636 Test loss: 0.3336 Test accuracy: 0.8617\n",
      "Epoch #7500 Loss: 0.3318 accuracy: 0.8636 Test loss: 0.3335 Test accuracy: 0.8617\n",
      "Epoch #8000 Loss: 0.3318 accuracy: 0.8636 Test loss: 0.3335 Test accuracy: 0.8617\n",
      "Epoch #8500 Loss: 0.3317 accuracy: 0.8636 Test loss: 0.3334 Test accuracy: 0.8617\n",
      "Epoch #9000 Loss: 0.3317 accuracy: 0.8636 Test loss: 0.3334 Test accuracy: 0.8617\n",
      "Epoch #9500 Loss: 0.3316 accuracy: 0.8636 Test loss: 0.3333 Test accuracy: 0.8617\n",
      "Epoch #10000 Loss: 0.3316 accuracy: 0.8636 Test loss: 0.3333 Test accuracy: 0.8617\n",
      "Epoch #10500 Loss: 0.3315 accuracy: 0.8636 Test loss: 0.3332 Test accuracy: 0.8617\n",
      "Epoch #11000 Loss: 0.3315 accuracy: 0.8636 Test loss: 0.3332 Test accuracy: 0.8617\n",
      "Epoch #11500 Loss: 0.3315 accuracy: 0.8636 Test loss: 0.3331 Test accuracy: 0.8617\n",
      "Epoch #12000 Loss: 0.3314 accuracy: 0.8636 Test loss: 0.3331 Test accuracy: 0.8618\n",
      "Epoch #12500 Loss: 0.3314 accuracy: 0.8636 Test loss: 0.3330 Test accuracy: 0.8618\n",
      "Epoch #13000 Loss: 0.3313 accuracy: 0.8636 Test loss: 0.3330 Test accuracy: 0.8618\n",
      "Epoch #13500 Loss: 0.3313 accuracy: 0.8636 Test loss: 0.3330 Test accuracy: 0.8618\n",
      "Epoch #14000 Loss: 0.3312 accuracy: 0.8636 Test loss: 0.3329 Test accuracy: 0.8618\n",
      "Epoch #14500 Loss: 0.3312 accuracy: 0.8636 Test loss: 0.3329 Test accuracy: 0.8618\n",
      "Epoch #15000 Loss: 0.3311 accuracy: 0.8636 Test loss: 0.3328 Test accuracy: 0.8618\n",
      "Epoch #15500 Loss: 0.3311 accuracy: 0.8636 Test loss: 0.3328 Test accuracy: 0.8618\n",
      "Epoch #16000 Loss: 0.3310 accuracy: 0.8636 Test loss: 0.3328 Test accuracy: 0.8618\n",
      "Epoch #16500 Loss: 0.3310 accuracy: 0.8636 Test loss: 0.3327 Test accuracy: 0.8618\n",
      "Epoch #17000 Loss: 0.3309 accuracy: 0.8636 Test loss: 0.3327 Test accuracy: 0.8618\n",
      "Epoch #17500 Loss: 0.3309 accuracy: 0.8636 Test loss: 0.3327 Test accuracy: 0.8618\n",
      "Epoch #18000 Loss: 0.3308 accuracy: 0.8636 Test loss: 0.3326 Test accuracy: 0.8618\n",
      "Epoch #18500 Loss: 0.3308 accuracy: 0.8636 Test loss: 0.3326 Test accuracy: 0.8618\n",
      "Epoch #19000 Loss: 0.3307 accuracy: 0.8636 Test loss: 0.3326 Test accuracy: 0.8618\n",
      "Epoch #19500 Loss: 0.3307 accuracy: 0.8636 Test loss: 0.3326 Test accuracy: 0.8618\n",
      "Epoch #20000 Loss: 0.3307 accuracy: 0.8636 Test loss: 0.3325 Test accuracy: 0.8618\n",
      "Epoch #20500 Loss: 0.3306 accuracy: 0.8636 Test loss: 0.3325 Test accuracy: 0.8618\n",
      "Epoch #21000 Loss: 0.3306 accuracy: 0.8636 Test loss: 0.3325 Test accuracy: 0.8618\n",
      "Epoch #21500 Loss: 0.3305 accuracy: 0.8636 Test loss: 0.3325 Test accuracy: 0.8618\n",
      "Epoch #22000 Loss: 0.3305 accuracy: 0.8636 Test loss: 0.3325 Test accuracy: 0.8618\n",
      "Epoch #22500 Loss: 0.3305 accuracy: 0.8636 Test loss: 0.3325 Test accuracy: 0.8618\n",
      "Epoch #23000 Loss: 0.3305 accuracy: 0.8636 Test loss: 0.3325 Test accuracy: 0.8618\n",
      "Epoch #23500 Loss: 0.3304 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #24000 Loss: 0.3304 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #24500 Loss: 0.3304 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #25000 Loss: 0.3304 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #25500 Loss: 0.3303 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #26000 Loss: 0.3303 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #26500 Loss: 0.3303 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #27000 Loss: 0.3303 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #27500 Loss: 0.3303 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #28000 Loss: 0.3302 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #28500 Loss: 0.3302 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #29000 Loss: 0.3302 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #29500 Loss: 0.3302 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #30000 Loss: 0.3302 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #30500 Loss: 0.3302 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #31000 Loss: 0.3302 accuracy: 0.8636 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #31500 Loss: 0.3302 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #32000 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #32500 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #33000 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #33500 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #34000 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8618\n",
      "Epoch #34500 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #35000 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #35500 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #36000 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #36500 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #37000 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #37500 Loss: 0.3301 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #38000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #38500 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #39000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #39500 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #40000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #40500 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #41000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #41500 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #42000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #42500 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #43000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #43500 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #44000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #44500 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #45000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #45500 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #46000 Loss: 0.3300 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #46500 Loss: 0.3299 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #47000 Loss: 0.3299 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #47500 Loss: 0.3299 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #48000 Loss: 0.3299 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #48500 Loss: 0.3299 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #49000 Loss: 0.3299 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n",
      "Epoch #49500 Loss: 0.3299 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #50000 Loss: 0.3299 accuracy: 0.8635 Test loss: 0.3324 Test accuracy: 0.8617\n"
     ]
    }
   ],
   "source": [
    "NUM_EPOCHS = 50000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels,})\n",
    "        if (epoch+1)% 500 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels})\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"accuracy: {:.4f}\".format(epoch_accuracy),\n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \n",
    "                  \"Test accuracy: {:.4f}\".format(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC is:0.514\n",
      "F1 is:0.040\n",
      "Recall is:0.052\n",
      "Precision is:0.044\n",
      "Hamming loss is:0.136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# On training \n",
    "print(\"AUC is:{:.3f}\".format(roc_auc_score(labels, epoch_output)))\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(labels, np.round(epoch_output),average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(labels, np.round(epoch_output))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC is:0.525\n",
      "F1 is:0.039\n",
      "Recall is:0.052\n",
      "Precision is:0.032\n",
      "Hamming loss is:0.138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/usr/local/lib/python3.5/dist-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "# On test\n",
    "print(\"AUC is:{:.3f}\".format(roc_auc_score(test_labels, val_output)))\n",
    "print(\"F1 is:{:.3f}\".format(f1_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Recall is:{:.3f}\".format(recall_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Precision is:{:.3f}\".format(precision_score(test_labels, np.round(val_output),average=\"macro\")))\n",
    "print(\"Hamming loss is:{:.3f}\".format(hamming_loss(test_labels, np.round(val_output))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 Loss: 0.2524 accuracy: 0.9101 Test loss: 0.3589 Test accuracy: 0.8537\n",
      "Epoch #1000 Loss: 0.2522 accuracy: 0.9103 Test loss: 0.3590 Test accuracy: 0.8537\n",
      "Epoch #1500 Loss: 0.2521 accuracy: 0.9104 Test loss: 0.3589 Test accuracy: 0.8537\n",
      "Epoch #2000 Loss: 0.2520 accuracy: 0.9105 Test loss: 0.3589 Test accuracy: 0.8537\n",
      "Epoch #2500 Loss: 0.2520 accuracy: 0.9106 Test loss: 0.3588 Test accuracy: 0.8537\n",
      "Epoch #3000 Loss: 0.2519 accuracy: 0.9107 Test loss: 0.3587 Test accuracy: 0.8537\n",
      "Epoch #3500 Loss: 0.2518 accuracy: 0.9108 Test loss: 0.3586 Test accuracy: 0.8537\n",
      "Epoch #4000 Loss: 0.2517 accuracy: 0.9109 Test loss: 0.3585 Test accuracy: 0.8537\n",
      "Epoch #4500 Loss: 0.2517 accuracy: 0.9110 Test loss: 0.3585 Test accuracy: 0.8537\n",
      "Epoch #5000 Loss: 0.2516 accuracy: 0.9110 Test loss: 0.3584 Test accuracy: 0.8537\n",
      "Epoch #5500 Loss: 0.2516 accuracy: 0.9111 Test loss: 0.3583 Test accuracy: 0.8537\n",
      "Epoch #6000 Loss: 0.2515 accuracy: 0.9111 Test loss: 0.3582 Test accuracy: 0.8537\n",
      "Epoch #6500 Loss: 0.2514 accuracy: 0.9111 Test loss: 0.3582 Test accuracy: 0.8537\n",
      "Epoch #7000 Loss: 0.2514 accuracy: 0.9111 Test loss: 0.3581 Test accuracy: 0.8537\n",
      "Epoch #7500 Loss: 0.2513 accuracy: 0.9111 Test loss: 0.3580 Test accuracy: 0.8537\n",
      "Epoch #8000 Loss: 0.2512 accuracy: 0.9111 Test loss: 0.3580 Test accuracy: 0.8537\n",
      "Epoch #8500 Loss: 0.2512 accuracy: 0.9111 Test loss: 0.3579 Test accuracy: 0.8537\n",
      "Epoch #9000 Loss: 0.2511 accuracy: 0.9112 Test loss: 0.3579 Test accuracy: 0.8537\n",
      "Epoch #9500 Loss: 0.2510 accuracy: 0.9111 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #10000 Loss: 0.2510 accuracy: 0.9111 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #10500 Loss: 0.2509 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #11000 Loss: 0.2508 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #11500 Loss: 0.2508 accuracy: 0.9112 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #12000 Loss: 0.2507 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #12500 Loss: 0.2506 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #13000 Loss: 0.2506 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #13500 Loss: 0.2505 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #14000 Loss: 0.2505 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #14500 Loss: 0.2504 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #15000 Loss: 0.2504 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #15500 Loss: 0.2503 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #16000 Loss: 0.2503 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #16500 Loss: 0.2503 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #17000 Loss: 0.2502 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #17500 Loss: 0.2502 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #18000 Loss: 0.2502 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #18500 Loss: 0.2502 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #19000 Loss: 0.2501 accuracy: 0.9111 Test loss: 0.3575 Test accuracy: 0.8537\n",
      "Epoch #19500 Loss: 0.2501 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #20000 Loss: 0.2501 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #20500 Loss: 0.2501 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #21000 Loss: 0.2501 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #21500 Loss: 0.2500 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #22000 Loss: 0.2500 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #22500 Loss: 0.2500 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #23000 Loss: 0.2500 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #23500 Loss: 0.2500 accuracy: 0.9111 Test loss: 0.3576 Test accuracy: 0.8537\n",
      "Epoch #24000 Loss: 0.2500 accuracy: 0.9111 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #24500 Loss: 0.2499 accuracy: 0.9111 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #25000 Loss: 0.2499 accuracy: 0.9111 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #25500 Loss: 0.2499 accuracy: 0.9111 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #26000 Loss: 0.2499 accuracy: 0.9111 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #26500 Loss: 0.2499 accuracy: 0.9111 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #27000 Loss: 0.2499 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #27500 Loss: 0.2499 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #28000 Loss: 0.2499 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #28500 Loss: 0.2499 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #29000 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #29500 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #30000 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #30500 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #31000 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #31500 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #32000 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #32500 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3577 Test accuracy: 0.8537\n",
      "Epoch #33000 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #33500 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #34000 Loss: 0.2498 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #34500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #35000 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #35500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #36000 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #36500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #37000 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #37500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #38000 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #38500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #39000 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #39500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #40000 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #40500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #41000 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #41500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #42000 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #42500 Loss: 0.2497 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #43000 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #43500 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #44000 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #44500 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #45000 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #45500 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #46000 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #46500 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #47000 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #47500 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #48000 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #48500 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #49000 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n",
      "Epoch #49500 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #50000 Loss: 0.2496 accuracy: 0.9112 Test loss: 0.3578 Test accuracy: 0.8537\n"
     ]
    }
   ],
   "source": [
    "ones_indices = np.nonzero(labels)\n",
    "ratio_of_hidden_samples = 0.4\n",
    "number_of_hidden_samples = int(len(ones_indices[0]) * ratio_of_hidden_samples)\n",
    "random_indices = random.sample(list(np.arange(len(ones_indices[0]))),number_of_hidden_samples)\n",
    "indices_to_hide = (ones_indices[0][random_indices] , ones_indices[1][random_indices])\n",
    "labels_with_missing_positives = np.copy(labels)\n",
    "for counter in range (number_of_hidden_samples):\n",
    "    labels_with_missing_positives[indices_to_hide[0][counter]][indices_to_hide[1][counter]] = 0\n",
    "    \n",
    "    \n",
    "# Training with missing labels with 40%\n",
    "NUM_EPOCHS = 50000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels_with_missing_positives})\n",
    "        if (epoch+1)% 500 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels})\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \n",
    "                  \"Test accuracy: {:.4f}\".format(val_accuracies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With fixed negative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_negative_weights = np.zeros_like(labels) + 1 \n",
    "train_positive_weights = np.zeros_like(labels) + 1\n",
    "for counter in range (number_of_hidden_samples):\n",
    "    train_negative_weights[indices_to_hide[0][counter]][indices_to_hide[1][counter]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_weights = tf.placeholder(tf.float32, [None,output_shape], name = \"Positive_weights\")\n",
    "negative_weights = tf.placeholder(tf.float32, [None, output_shape], name=\"negative_weights\")\n",
    "my_weights_loss = weighted_loss(y_true= y, y_pred= output,\n",
    "                              positive_weights= positive_weights, negative_weights= negative_weights)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(my_weights_loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 Loss: 0.2553 Weighted Loss: 0.2367 accuracy: 0.9084 Test loss: 0.3485 Test accuracy: 0.8573\n",
      "Epoch #1000 Loss: 0.2551 Weighted Loss: 0.2365 accuracy: 0.9085 Test loss: 0.3486 Test accuracy: 0.8573\n",
      "Epoch #1500 Loss: 0.2551 Weighted Loss: 0.2364 accuracy: 0.9086 Test loss: 0.3485 Test accuracy: 0.8573\n",
      "Epoch #2000 Loss: 0.2550 Weighted Loss: 0.2363 accuracy: 0.9086 Test loss: 0.3484 Test accuracy: 0.8573\n",
      "Epoch #2500 Loss: 0.2549 Weighted Loss: 0.2363 accuracy: 0.9087 Test loss: 0.3484 Test accuracy: 0.8574\n",
      "Epoch #3000 Loss: 0.2548 Weighted Loss: 0.2362 accuracy: 0.9087 Test loss: 0.3483 Test accuracy: 0.8574\n",
      "Epoch #3500 Loss: 0.2548 Weighted Loss: 0.2361 accuracy: 0.9088 Test loss: 0.3482 Test accuracy: 0.8574\n",
      "Epoch #4000 Loss: 0.2547 Weighted Loss: 0.2361 accuracy: 0.9088 Test loss: 0.3481 Test accuracy: 0.8574\n",
      "Epoch #4500 Loss: 0.2547 Weighted Loss: 0.2360 accuracy: 0.9089 Test loss: 0.3481 Test accuracy: 0.8574\n",
      "Epoch #5000 Loss: 0.2546 Weighted Loss: 0.2360 accuracy: 0.9090 Test loss: 0.3480 Test accuracy: 0.8574\n",
      "Epoch #5500 Loss: 0.2546 Weighted Loss: 0.2359 accuracy: 0.9090 Test loss: 0.3479 Test accuracy: 0.8574\n",
      "Epoch #6000 Loss: 0.2545 Weighted Loss: 0.2358 accuracy: 0.9091 Test loss: 0.3478 Test accuracy: 0.8574\n",
      "Epoch #6500 Loss: 0.2544 Weighted Loss: 0.2358 accuracy: 0.9091 Test loss: 0.3478 Test accuracy: 0.8574\n",
      "Epoch #7000 Loss: 0.2544 Weighted Loss: 0.2357 accuracy: 0.9091 Test loss: 0.3477 Test accuracy: 0.8574\n",
      "Epoch #7500 Loss: 0.2543 Weighted Loss: 0.2357 accuracy: 0.9091 Test loss: 0.3476 Test accuracy: 0.8574\n",
      "Epoch #8000 Loss: 0.2543 Weighted Loss: 0.2356 accuracy: 0.9091 Test loss: 0.3476 Test accuracy: 0.8574\n",
      "Epoch #8500 Loss: 0.2542 Weighted Loss: 0.2356 accuracy: 0.9090 Test loss: 0.3475 Test accuracy: 0.8574\n",
      "Epoch #9000 Loss: 0.2542 Weighted Loss: 0.2355 accuracy: 0.9091 Test loss: 0.3475 Test accuracy: 0.8574\n",
      "Epoch #9500 Loss: 0.2541 Weighted Loss: 0.2355 accuracy: 0.9091 Test loss: 0.3474 Test accuracy: 0.8574\n",
      "Epoch #10000 Loss: 0.2541 Weighted Loss: 0.2354 accuracy: 0.9091 Test loss: 0.3473 Test accuracy: 0.8574\n",
      "Epoch #10500 Loss: 0.2540 Weighted Loss: 0.2354 accuracy: 0.9091 Test loss: 0.3473 Test accuracy: 0.8574\n",
      "Epoch #11000 Loss: 0.2540 Weighted Loss: 0.2353 accuracy: 0.9091 Test loss: 0.3472 Test accuracy: 0.8574\n",
      "Epoch #11500 Loss: 0.2539 Weighted Loss: 0.2353 accuracy: 0.9091 Test loss: 0.3472 Test accuracy: 0.8574\n",
      "Epoch #12000 Loss: 0.2539 Weighted Loss: 0.2352 accuracy: 0.9090 Test loss: 0.3471 Test accuracy: 0.8574\n",
      "Epoch #12500 Loss: 0.2538 Weighted Loss: 0.2352 accuracy: 0.9091 Test loss: 0.3471 Test accuracy: 0.8574\n",
      "Epoch #13000 Loss: 0.2538 Weighted Loss: 0.2351 accuracy: 0.9091 Test loss: 0.3471 Test accuracy: 0.8574\n",
      "Epoch #13500 Loss: 0.2537 Weighted Loss: 0.2351 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8574\n",
      "Epoch #14000 Loss: 0.2537 Weighted Loss: 0.2350 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8574\n",
      "Epoch #14500 Loss: 0.2536 Weighted Loss: 0.2350 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8574\n",
      "Epoch #15000 Loss: 0.2536 Weighted Loss: 0.2350 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8574\n",
      "Epoch #15500 Loss: 0.2535 Weighted Loss: 0.2349 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #16000 Loss: 0.2535 Weighted Loss: 0.2349 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #16500 Loss: 0.2535 Weighted Loss: 0.2348 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #17000 Loss: 0.2534 Weighted Loss: 0.2348 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #17500 Loss: 0.2534 Weighted Loss: 0.2348 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #18000 Loss: 0.2534 Weighted Loss: 0.2347 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #18500 Loss: 0.2533 Weighted Loss: 0.2347 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #19000 Loss: 0.2533 Weighted Loss: 0.2347 accuracy: 0.9091 Test loss: 0.3468 Test accuracy: 0.8574\n",
      "Epoch #19500 Loss: 0.2533 Weighted Loss: 0.2347 accuracy: 0.9091 Test loss: 0.3468 Test accuracy: 0.8574\n",
      "Epoch #20000 Loss: 0.2533 Weighted Loss: 0.2346 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #20500 Loss: 0.2532 Weighted Loss: 0.2346 accuracy: 0.9091 Test loss: 0.3468 Test accuracy: 0.8574\n",
      "Epoch #21000 Loss: 0.2532 Weighted Loss: 0.2346 accuracy: 0.9091 Test loss: 0.3468 Test accuracy: 0.8574\n",
      "Epoch #21500 Loss: 0.2532 Weighted Loss: 0.2346 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #22000 Loss: 0.2532 Weighted Loss: 0.2346 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #22500 Loss: 0.2532 Weighted Loss: 0.2345 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8574\n",
      "Epoch #23000 Loss: 0.2531 Weighted Loss: 0.2345 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #23500 Loss: 0.2531 Weighted Loss: 0.2345 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #24000 Loss: 0.2531 Weighted Loss: 0.2345 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #24500 Loss: 0.2531 Weighted Loss: 0.2345 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #25000 Loss: 0.2531 Weighted Loss: 0.2345 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #25500 Loss: 0.2531 Weighted Loss: 0.2345 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #26000 Loss: 0.2531 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #26500 Loss: 0.2531 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #27000 Loss: 0.2530 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #27500 Loss: 0.2530 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #28000 Loss: 0.2530 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #28500 Loss: 0.2530 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #29000 Loss: 0.2530 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #29500 Loss: 0.2530 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #30000 Loss: 0.2530 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #30500 Loss: 0.2530 Weighted Loss: 0.2344 accuracy: 0.9091 Test loss: 0.3469 Test accuracy: 0.8573\n",
      "Epoch #31000 Loss: 0.2530 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #31500 Loss: 0.2530 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #32000 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #32500 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #33000 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #33500 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #34000 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #34500 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #35000 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #35500 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #36000 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #36500 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #37000 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #37500 Loss: 0.2529 Weighted Loss: 0.2343 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #38000 Loss: 0.2529 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #38500 Loss: 0.2529 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #39000 Loss: 0.2529 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #39500 Loss: 0.2529 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #40000 Loss: 0.2529 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #40500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #41000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #41500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #42000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #42500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #43000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #43500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #44000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #44500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #45000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #45500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #46000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #46500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #47000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #47500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #48000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #48500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #49000 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #49500 Loss: 0.2528 Weighted Loss: 0.2342 accuracy: 0.9091 Test loss: 0.3470 Test accuracy: 0.8573\n",
      "Epoch #50000 Loss: 0.2528 Weighted Loss: 0.2341 accuracy: 0.9091 Test loss: 0.3471 Test accuracy: 0.8573\n"
     ]
    }
   ],
   "source": [
    "# Training with negative weights!\n",
    "NUM_EPOCHS = 50000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_my_weights_loss, epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([my_weights_loss, loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         features,y: labels_with_missing_positives,positive_weights: train_positive_weights,\n",
    "                                                                                                  negative_weights: train_negative_weights})\n",
    "        if (epoch+1)% 500 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels})\n",
    "            print(\"Epoch #{}\".format(epoch+1), \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"Weighted Loss: {:.4f}\".format(epoch_my_weights_loss),\"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \"Test accuracy: {:.4f}\".format(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
