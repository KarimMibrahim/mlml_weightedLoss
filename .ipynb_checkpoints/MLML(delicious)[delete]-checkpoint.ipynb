{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "import numpy as np \n",
    "import os\n",
    "import scipy\n",
    "from scipy.io import loadmat\n",
    "import pandas as pd\n",
    "import tensorflow as tf \n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, f1_score, cohen_kappa_score, hamming_loss, zero_one_loss, coverage_error, average_precision_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import random \n",
    "import matplotlib.pyplot as plt\n",
    "from time import strftime, localtime\n",
    "from sklearn.model_selection import KFold\n",
    "random.seed = 11\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples is: 5000\n",
      "#features is: 550, #labels is: 33\n",
      "Ratio of positive labels is: 4.43%\n"
     ]
    }
   ],
   "source": [
    "# Reading dataset\n",
    "educationDataset = loadmat(\"/home/karim/Documents/research/sourceCode/MLML/mlml_weightedLoss/Datasets/MulanDatasets/education.mat\")\n",
    "\n",
    "features = educationDataset['train_data']\n",
    "test_features = educationDataset['test_data']\n",
    "\n",
    "labels = educationDataset['train_target'].T\n",
    "test_labels = educationDataset['test_target'].T\n",
    "\n",
    "\"\"\"\n",
    "Split ratio is strange: 40% training and 60% testing, we merge and data and resplit with 70/30 split\n",
    "\"\"\"\n",
    "features = np.append(features,test_features,axis = 0)\n",
    "labels = np.append(labels,test_labels,axis = 0)\n",
    "\n",
    "print(\"Number of samples is: {}\".format(len(features)))\n",
    "print(\"#features is: {}, #labels is: {}\".format(features.shape[1],labels.shape[1]))\n",
    "print(\"Ratio of positive labels is: {:.2f}%\".format(100 * labels.sum()/(labels.shape[0]*labels.shape[1])))\n",
    "\n",
    "splitter = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "#features, test_features, labels, test_labels = train_test_split(features, labels, test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NN approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "code_folding": [
     1,
     6,
     12,
     18,
     27,
     52
    ]
   },
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "def get_weights(shape):\n",
    "    w = tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "    #variable_summaries(w)\n",
    "    return w\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    b = tf.Variable(initial)\n",
    "    #variable_summaries(b)\n",
    "    return b\n",
    "\n",
    "def full_layer(input, size):\n",
    "    in_size = int(input.get_shape()[1])\n",
    "    W = get_weights([in_size, size])\n",
    "    b = bias_variable([size])\n",
    "    return tf.matmul(input, W) + b\n",
    "\n",
    "def weighted_loss(y_true, y_pred, positive_weights, negative_weights):\n",
    "    # clip to prevent NaN's and Inf's\n",
    "    y_pred = tf.clip_by_value(y_pred, 1e-7, 1-1e-7, name=None)\n",
    "    #y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n",
    "    # calc\n",
    "    loss = (-y_true * tf.log(y_pred) * positive_weights) - ((1.0 - y_true) * tf.log(1.0 - y_pred) * negative_weights)\n",
    "    loss = tf.reduce_mean(loss)\n",
    "    return loss\n",
    "\n",
    "def evaluation_report(folds_metrics,evaluation_file_path,header_note):\n",
    "    metrics_mean = np.mean(folds_metrics, axis = 0)\n",
    "    metrics_std = np.std(folds_metrics, axis = 0) * 1.96 # for 95% confidence interval\n",
    "    print(header_note)\n",
    "    print(\"===================\")\n",
    "    print(\"Test set evaluation\")\n",
    "    print(\"Hamming loss is:{:.3f} (+/-{:.3f})\".format(metrics_mean[0],metrics_std[0]))\n",
    "    print(\"Zero-one loss is:{:.3f} (+/-{:.3f})\".format(metrics_mean[1],metrics_std[1]))\n",
    "    print(\"Coverage error is:{:.3f} (+/-{:.3f})\".format(metrics_mean[2],metrics_std[2]))\n",
    "    print(\"F1 is:{:.3f} (+/-{:.3f})\".format(metrics_mean[3],metrics_std[3]))\n",
    "    print(\"Recall is:{:.3f} (+/-{:.3f})\".format(metrics_mean[4],metrics_std[4]))\n",
    "    print(\"Precision is:{:.3f} (+/-{:.3f})\".format(metrics_mean[5],metrics_std[5]))\n",
    "    print(\"Average Precision is:{:.3f} (+/-{:.3f})\".format(metrics_mean[6],metrics_std[6]))\n",
    "    \n",
    "    with open(evaluation_file_path, \"a+\") as f:\n",
    "        f.write(\"===================\\n\" + header_note + \"\\n\")\n",
    "        f.write(\"Hamming loss is:{:.3f} (+/-{:.3f})\".format(metrics_mean[0],metrics_std[0]) + \"\\n\"+\n",
    "                \"Zero-one loss is:{:.3f} (+/-{:.3f})\".format(metrics_mean[1],metrics_std[1]) + \"\\n\"+\n",
    "                \"Coverage error is:{:.3f} (+/-{:.3f})\".format(metrics_mean[2],metrics_std[2]) + \"\\n\"+\n",
    "                \"F1 is:{:.3f} (+/-{:.3f})\".format(metrics_mean[3],metrics_std[3]) + \"\\n\"+\n",
    "                \"Recall is:{:.3f} (+/-{:.3f})\".format(metrics_mean[4],metrics_std[4]) + \"\\n\"+\n",
    "                \"Precision is:{:.3f} (+/-{:.3f})\".format(metrics_mean[5],metrics_std[5]) + \"\\n\"+\n",
    "                \"Average Precision is:{:.3f} (+/-{:.3f})\".format(metrics_mean[6],metrics_std[6])\n",
    "               + \"\\n\\n\")\n",
    "        \n",
    "def evaluation_metrics_per_fold(test_labels, test_probs):\n",
    "    # ignoring auc for now because of error of undefined case of a class with no ones\n",
    "    try:\n",
    "        auc = roc_auc_score(test_labels, val_output)\n",
    "    except:\n",
    "        pass\n",
    "    HL = hamming_loss(test_labels, np.round(test_probs))\n",
    "    one_loss = zero_one_loss(test_labels, np.round(test_probs))\n",
    "    cover = coverage_error(test_labels, test_probs)\n",
    "    f1 = f1_score(test_labels, np.round(test_probs),average=\"micro\")\n",
    "    recall = recall_score(test_labels, np.round(test_probs),average=\"micro\")\n",
    "    precision = precision_score(test_labels, np.round(test_probs),average=\"micro\")\n",
    "    average_precision = average_precision_score(test_labels, test_probs,average=\"micro\")\n",
    "    metrics = [HL, one_loss, cover, f1, recall, precision, average_precision]\n",
    "    return metrics\n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define a 3 layers network to train \n",
    "input_shape = features.shape[1]\n",
    "output_shape = labels.shape[1]\n",
    "hidden_layer_1_shape = 300\n",
    "hidden_layer_2_shape = 200\n",
    "hidden_layer_3_shape = 100\n",
    "\n",
    "y = tf.placeholder(tf.float32, [None, output_shape], name=\"true_labels\")\n",
    "x_input = tf.placeholder(tf.float32, [None,input_shape],name=\"input_layer\")\n",
    "current_keep_prob = tf.placeholder(tf.float32, name=\"dropout_rate\")\n",
    "h1 = tf.nn.tanh(full_layer(x_input, hidden_layer_1_shape))\n",
    "h2 = tf.nn.tanh(full_layer(h1, hidden_layer_2_shape))\n",
    "h3 = tf.nn.tanh(full_layer(h2, hidden_layer_3_shape))\n",
    "dropped = tf.nn.dropout(h3, keep_prob=current_keep_prob)\n",
    "logits = full_layer(dropped,output_shape)\n",
    "output = tf.nn.sigmoid(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Prepare results report \n",
    "Experiment_name = \"Education_weightedloss\"\n",
    "experiment_time = strftime(\"%d-%m_%H:%M\", localtime())\n",
    "saving_dir = \"/home/karim/Documents/research/sourceCode/MLML/mlml_weightedLoss/Experiment_results/\"\n",
    "exp_dir = os.path.join(saving_dir,Experiment_name,experiment_time)\n",
    "os.makedirs(exp_dir)\n",
    "model_output_dir = os.path.join(exp_dir,\"model_output\")\n",
    "os.mkdir(model_output_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on complete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Define model parameters\n",
    "# using weighted cross entropy because dataset is sparse and we need to weight positives more\n",
    "#loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=logits, labels=y))\n",
    "POSITIVE_WEIGHT = 5\n",
    "loss = tf.reduce_mean(tf.nn.weighted_cross_entropy_with_logits(logits=logits, labels=y,pos_weight = POSITIVE_WEIGHT))\n",
    "\n",
    "# Learning rate decay\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "learning_rate = tf.train.exponential_decay(learning_rate=0.1, global_step=global_step, decay_steps=1000,\n",
    "                                          decay_rate=0.95,staircase=True)\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss,global_step=global_step)\n",
    "correct_prediction = tf.equal(tf.round(output), y)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Evaluate on fold 1\n",
      "Epoch #3000 LR: 0.0857 Loss: 0.3386 accuracy: 0.9315 Test loss: 0.3298 Test accuracy: 0.9350\n"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "NUM_EPOCHS = 15000\n",
    "\n",
    "fold = 0\n",
    "folds_metrics = []\n",
    "for train_index, test_index in splitter.split(features, labels):\n",
    "    fold += 1\n",
    "    print(\"Train/Evaluate on fold %d\" % fold)\n",
    "    train_features, test_features = features[train_index], features[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(NUM_EPOCHS):\n",
    "            epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                             train_features,y: train_labels,\n",
    "                                                                                             current_keep_prob: 0.3,})\n",
    "            if (epoch+1)% 3000 == 0:\n",
    "                val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                              x_input: test_features,\n",
    "                                                                                              y:test_labels,\n",
    "                                                                                              current_keep_prob: 1.0})\n",
    "                print(\"Epoch #{}\".format(epoch+1), \"LR: {:.4f}\".format(current_learning_rate),\n",
    "                      \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                      \"accuracy: {:.4f}\".format(epoch_accuracy),\n",
    "                      \"Test loss: {:.4f}\".format(val_losses), \n",
    "                      \"Test accuracy: {:.4f}\".format(val_accuracies))\n",
    "    np.savetxt(os.path.join(model_output_dir,'groundtruth_' + str(fold) + '.out'), test_labels, delimiter=',')\n",
    "    np.savetxt(os.path.join(model_output_dir, 'output' + str(fold) + '.out'), val_output, delimiter=',')\n",
    "    folds_metrics.append(evaluation_metrics_per_fold(test_labels,val_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nthresholds = np.arange(0, 1, 0.01)\\nf1_array = np.zeros((output_shape, len(thresholds)))\\nfor idx in range(output_shape):\\n    f1_array[idx, :] = [\\n        f1_score(labels[:, idx], np.clip(np.round(epoch_output[:, idx] - threshold + 0.5), 0, 1))\\n        for threshold in thresholds]\\nthreshold_arg = np.argmax(f1_array, axis=1)\\nthreshold_per_class = thresholds[threshold_arg]\\n\\n# Applying thresholds optimized per class\\nmodel_output_rounded = np.zeros_like(epoch_output)\\nfor idx in range(output_shape):\\n    model_output_rounded[:, idx] = np.clip(np.round(epoch_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjusting threshold \n",
    "\"\"\"\n",
    "thresholds = np.arange(0, 1, 0.01)\n",
    "f1_array = np.zeros((output_shape, len(thresholds)))\n",
    "for idx in range(output_shape):\n",
    "    f1_array[idx, :] = [\n",
    "        f1_score(train_labels[:, idx], np.clip(np.round(epoch_output[:, idx] - threshold + 0.5), 0, 1))\n",
    "        for threshold in thresholds]\n",
    "threshold_arg = np.argmax(f1_array, axis=1)\n",
    "threshold_per_class = thresholds[threshold_arg]\n",
    "\n",
    "# Applying thresholds optimized per class\n",
    "model_output_rounded = np.zeros_like(epoch_output)\n",
    "for idx in range(output_shape):\n",
    "    model_output_rounded[:, idx] = np.clip(np.round(epoch_output[:, idx] - threshold_per_class[idx] + 0.5), 0, 1)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No missing labels\n",
      "Training set evaluation\n",
      "F1 is:0.487\n",
      "Recall is:0.664\n",
      "Precision is:0.384\n",
      "Average Precision is:0.512\n",
      "Hamming loss is:0.062\n",
      "Zero-one loss is:0.890\n",
      "Coverage error is:3.777\n",
      "===================\n",
      "Test set evaluation\n",
      "F1 is:0.452\n",
      "Recall is:0.584\n",
      "Precision is:0.368\n",
      "Average Precision is:0.490\n",
      "Hamming loss is:0.062\n",
      "Zero-one loss is:0.866\n",
      "Coverage error is:4.313\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "evaluation_report(folds_metrics,os.path.join(exp_dir,\"evaluation_report.txt\"),\"No missing labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With missing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Create missing labels\n",
    "ones_indices = np.nonzero(train_labels)\n",
    "ratio_of_hidden_samples = 0.4\n",
    "number_of_hidden_samples = int(len(ones_indices[0]) * ratio_of_hidden_samples)\n",
    "random_indices = random.sample(list(np.arange(len(ones_indices[0]))),number_of_hidden_samples)\n",
    "indices_to_hide = (ones_indices[0][random_indices] , ones_indices[1][random_indices])\n",
    "labels_with_missing_positives = np.copy(train_labels)\n",
    "for counter in range (number_of_hidden_samples):\n",
    "    labels_with_missing_positives[indices_to_hide[0][counter]][indices_to_hide[1][counter]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #2000 LR: 0.0903 Loss: 0.2832 accuracy: 0.9605 Test loss: 0.3719 Test accuracy: 0.9486\n",
      "Epoch #4000 LR: 0.0815 Loss: 0.2660 accuracy: 0.9609 Test loss: 0.3521 Test accuracy: 0.9559\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2544 accuracy: 0.9597 Test loss: 0.3405 Test accuracy: 0.9576\n",
      "Epoch #8000 LR: 0.0663 Loss: 0.2489 accuracy: 0.9592 Test loss: 0.3362 Test accuracy: 0.9583\n",
      "Epoch #10000 LR: 0.0599 Loss: 0.2387 accuracy: 0.9603 Test loss: 0.3346 Test accuracy: 0.9587\n",
      "Epoch #12000 LR: 0.0540 Loss: 0.2347 accuracy: 0.9601 Test loss: 0.3343 Test accuracy: 0.9584\n",
      "Epoch #14000 LR: 0.0488 Loss: 0.2301 accuracy: 0.9600 Test loss: 0.3352 Test accuracy: 0.9578\n"
     ]
    }
   ],
   "source": [
    "# Training with missing labels with 40%\n",
    "NUM_EPOCHS = 15000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         train_features,y: labels_with_missing_positives,\n",
    "                                                                                         current_keep_prob: 0.3})\n",
    "        if (epoch+1)% 2000 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels,\n",
    "                                                                                          current_keep_prob: 1.0})\n",
    "            print(\"Epoch #{}\".format(epoch+1),  \"LR: {:.4f}\".format(current_learning_rate),\n",
    "                  \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \n",
    "                  \"Test accuracy: {:.4f}\".format(val_accuracies))\n",
    "            if (epoch+1) == NUM_EPOCHS:\n",
    "                print(\"====================================== \\\n",
    "                      \\n\\nFinal test accuracy: {:.4f}\".format(val_accuracies))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40% missing labels, no weighted loss\n",
      "Training set evaluation\n",
      "F1 is:0.450\n",
      "Recall is:0.423\n",
      "Precision is:0.480\n",
      "Average Precision is:0.446\n",
      "Hamming loss is:0.046\n",
      "Zero-one loss is:0.792\n",
      "Coverage error is:4.409\n",
      "===================\n",
      "Test set evaluation\n",
      "F1 is:0.453\n",
      "Recall is:0.399\n",
      "Precision is:0.525\n",
      "Average Precision is:0.477\n",
      "Hamming loss is:0.042\n",
      "Zero-one loss is:0.738\n",
      "Coverage error is:4.473\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "evaluation_report(train_labels,epoch_output,test_labels,val_output,\n",
    "                  os.path.join(exp_dir,\"evaluation_report.txt\"),\"40% missing labels, no weighted loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With fixed negative weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# Defining weights for missing labels\n",
    "train_negative_weights = np.zeros_like(train_labels) + 1 \n",
    "train_positive_weights = np.zeros_like(train_labels) + 5 # We make positive weight 5 becuase of data imbalance\n",
    "for counter in range (number_of_hidden_samples):\n",
    "    train_negative_weights[indices_to_hide[0][counter]][indices_to_hide[1][counter]] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1119 11:47:30.831513 139659898185472 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Adding the weighted loss to the model\n",
    "positive_weights = tf.placeholder(tf.float32, [None,output_shape], name = \"Positive_weights\")\n",
    "negative_weights = tf.placeholder(tf.float32, [None, output_shape], name=\"negative_weights\")\n",
    "my_weights_loss = weighted_loss(y_true= y, y_pred= output,\n",
    "                              positive_weights= positive_weights, negative_weights= negative_weights)\n",
    "\n",
    "train_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(my_weights_loss,global_step=global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #500 LR: 0.1000 Loss: 0.3056 Weighted Loss: 0.2971 accuracy: 0.9437 Test loss: 0.3785 Test accuracy: 0.9454\n",
      "Epoch #1000 LR: 0.0950 Loss: 0.2914 Weighted Loss: 0.2828 accuracy: 0.9523 Test loss: 0.3736 Test accuracy: 0.9455\n",
      "Epoch #1500 LR: 0.0950 Loss: 0.2844 Weighted Loss: 0.2757 accuracy: 0.9537 Test loss: 0.3696 Test accuracy: 0.9458\n",
      "Epoch #2000 LR: 0.0903 Loss: 0.2797 Weighted Loss: 0.2710 accuracy: 0.9540 Test loss: 0.3648 Test accuracy: 0.9461\n",
      "Epoch #2500 LR: 0.0903 Loss: 0.2765 Weighted Loss: 0.2674 accuracy: 0.9541 Test loss: 0.3591 Test accuracy: 0.9470\n",
      "Epoch #3000 LR: 0.0857 Loss: 0.2716 Weighted Loss: 0.2621 accuracy: 0.9537 Test loss: 0.3530 Test accuracy: 0.9484\n",
      "Epoch #3500 LR: 0.0857 Loss: 0.2678 Weighted Loss: 0.2576 accuracy: 0.9531 Test loss: 0.3474 Test accuracy: 0.9495\n",
      "Epoch #4000 LR: 0.0815 Loss: 0.2650 Weighted Loss: 0.2544 accuracy: 0.9535 Test loss: 0.3426 Test accuracy: 0.9509\n",
      "Epoch #4500 LR: 0.0815 Loss: 0.2607 Weighted Loss: 0.2495 accuracy: 0.9540 Test loss: 0.3389 Test accuracy: 0.9518\n",
      "Epoch #5000 LR: 0.0774 Loss: 0.2585 Weighted Loss: 0.2470 accuracy: 0.9540 Test loss: 0.3359 Test accuracy: 0.9524\n",
      "Epoch #5500 LR: 0.0774 Loss: 0.2544 Weighted Loss: 0.2423 accuracy: 0.9543 Test loss: 0.3336 Test accuracy: 0.9532\n",
      "Epoch #6000 LR: 0.0735 Loss: 0.2539 Weighted Loss: 0.2416 accuracy: 0.9548 Test loss: 0.3315 Test accuracy: 0.9536\n",
      "Epoch #6500 LR: 0.0735 Loss: 0.2510 Weighted Loss: 0.2381 accuracy: 0.9548 Test loss: 0.3302 Test accuracy: 0.9538\n",
      "Epoch #7000 LR: 0.0698 Loss: 0.2472 Weighted Loss: 0.2341 accuracy: 0.9547 Test loss: 0.3291 Test accuracy: 0.9540\n",
      "Epoch #7500 LR: 0.0698 Loss: 0.2449 Weighted Loss: 0.2311 accuracy: 0.9557 Test loss: 0.3282 Test accuracy: 0.9543\n",
      "Epoch #8000 LR: 0.0663 Loss: 0.2440 Weighted Loss: 0.2302 accuracy: 0.9547 Test loss: 0.3275 Test accuracy: 0.9544\n",
      "Epoch #8500 LR: 0.0663 Loss: 0.2401 Weighted Loss: 0.2261 accuracy: 0.9556 Test loss: 0.3272 Test accuracy: 0.9550\n",
      "Epoch #9000 LR: 0.0630 Loss: 0.2410 Weighted Loss: 0.2268 accuracy: 0.9557 Test loss: 0.3269 Test accuracy: 0.9551\n",
      "Epoch #9500 LR: 0.0630 Loss: 0.2395 Weighted Loss: 0.2244 accuracy: 0.9544 Test loss: 0.3267 Test accuracy: 0.9552\n",
      "Epoch #10000 LR: 0.0599 Loss: 0.2378 Weighted Loss: 0.2232 accuracy: 0.9548 Test loss: 0.3268 Test accuracy: 0.9553\n",
      "Epoch #10500 LR: 0.0599 Loss: 0.2368 Weighted Loss: 0.2218 accuracy: 0.9551 Test loss: 0.3269 Test accuracy: 0.9554\n",
      "Epoch #11000 LR: 0.0569 Loss: 0.2351 Weighted Loss: 0.2201 accuracy: 0.9555 Test loss: 0.3270 Test accuracy: 0.9553\n",
      "Epoch #11500 LR: 0.0569 Loss: 0.2362 Weighted Loss: 0.2207 accuracy: 0.9553 Test loss: 0.3273 Test accuracy: 0.9552\n",
      "Epoch #12000 LR: 0.0540 Loss: 0.2349 Weighted Loss: 0.2197 accuracy: 0.9554 Test loss: 0.3275 Test accuracy: 0.9551\n",
      "Epoch #12500 LR: 0.0540 Loss: 0.2326 Weighted Loss: 0.2168 accuracy: 0.9548 Test loss: 0.3280 Test accuracy: 0.9549\n",
      "Epoch #13000 LR: 0.0513 Loss: 0.2304 Weighted Loss: 0.2143 accuracy: 0.9549 Test loss: 0.3285 Test accuracy: 0.9551\n",
      "Epoch #13500 LR: 0.0513 Loss: 0.2323 Weighted Loss: 0.2165 accuracy: 0.9551 Test loss: 0.3289 Test accuracy: 0.9549\n",
      "Epoch #14000 LR: 0.0488 Loss: 0.2298 Weighted Loss: 0.2136 accuracy: 0.9543 Test loss: 0.3292 Test accuracy: 0.9549\n",
      "Epoch #14500 LR: 0.0488 Loss: 0.2259 Weighted Loss: 0.2100 accuracy: 0.9553 Test loss: 0.3299 Test accuracy: 0.9547\n",
      "Epoch #15000 LR: 0.0463 Loss: 0.2264 Weighted Loss: 0.2100 accuracy: 0.9556 Test loss: 0.3304 Test accuracy: 0.9549\n",
      "======================================                       \n",
      "\n",
      "Final test accuracy: 0.9549\n"
     ]
    }
   ],
   "source": [
    "# Training with negative weights!\n",
    "NUM_EPOCHS = 15000\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        epoch_my_weights_loss, epoch_loss, epoch_accuracy,epoch_output, _ = sess.run([my_weights_loss, loss, accuracy,output, train_step],feed_dict={x_input: \n",
    "                                                                                         train_features,y: labels_with_missing_positives,positive_weights: train_positive_weights,\n",
    "                                                                                                  negative_weights: train_negative_weights,\n",
    "                                                                                                  current_keep_prob: 0.3})\n",
    "        if (epoch+1)% 2000 == 0:\n",
    "            val_losses, val_accuracies, val_output,current_learning_rate = sess.run([loss, accuracy,output,learning_rate],feed_dict={\n",
    "                                                                                          x_input: test_features,\n",
    "                                                                                          y:test_labels,\n",
    "                                                                                          current_keep_prob: 1.0})\n",
    "            print(\"Epoch #{}\".format(epoch+1),  \"LR: {:.4f}\".format(current_learning_rate),\n",
    "                  \"Loss: {:.4f}\".format(epoch_loss), \n",
    "                  \"Weighted Loss: {:.4f}\".format(epoch_my_weights_loss),\"accuracy: {:.4f}\".format(epoch_accuracy), \n",
    "                  \"Test loss: {:.4f}\".format(val_losses), \"Test accuracy: {:.4f}\".format(val_accuracies))\n",
    "            if (epoch+1) == NUM_EPOCHS:\n",
    "                print(\"====================================== \\\n",
    "                      \\n\\nFinal test accuracy: {:.4f}\".format(val_accuracies))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weighted loss with 40% missing\n",
      "Training set evaluation\n",
      "F1 is:0.485\n",
      "Recall is:0.496\n",
      "Precision is:0.475\n",
      "Average Precision is:0.483\n",
      "Hamming loss is:0.047\n",
      "Zero-one loss is:0.780\n",
      "Coverage error is:4.338\n",
      "===================\n",
      "Test set evaluation\n",
      "F1 is:0.463\n",
      "Recall is:0.444\n",
      "Precision is:0.484\n",
      "Average Precision is:0.479\n",
      "Hamming loss is:0.045\n",
      "Zero-one loss is:0.736\n",
      "Coverage error is:4.452\n"
     ]
    }
   ],
   "source": [
    "#Evaluation\n",
    "evaluation_report(train_labels,epoch_output,test_labels,val_output,\n",
    "                  os.path.join(exp_dir,\"evaluation_report.txt\"),\"Weighted loss with 40% missing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_reg = xgb.XGBRegressor(objective ='reg:linear', colsample_bytree = 0.3, learning_rate = 0.1,\n",
    "                max_depth = 5, alpha = 10, n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-8054be8fe2e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mxg_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxg_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "xg_reg.fit(X_train,y_train)\n",
    "\n",
    "preds = xg_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = KFold(n_splits=5, shuffle=True, random_state=0)\n",
    "for train_index, test_index in skf.split(features, labels):\n",
    "    train_features, test_features = features[train_index], features[test_index]\n",
    "    train_labels, test_labels = labels[train_index], labels[test_index]\n",
    "    # Train model \n",
    "    # Evaluate model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
